---
layout: post
author: Ryan
tags: [writing]
---
The topic of my last poll came from an article by John Searle where he brings up the Chinese room example (I originally heard about it from Javin, I'm really glad you mentioned it to me because it's super interesting and I'm curious to hear your thoughts on it). The short version is that Searle doesn't believe a computer could ever be said to actually think, or to experience consciousness. His hypothetical experiment is very convincing, I'm not going to describe it here but I highly recommend reading it (http://cogprints.org/7150/1/10.1.1.83.5248.pdf). If you want the extra short version check wikipedia.

I think Searle is absolutely right that current implementations of computer programs cannot think and will not be able to think anytime soon. However I think Searle is wrong that computer programs cannot possibly experience consciousness or real thinking. In particular I think he's wrong in his response to the brain simulator reply (case III in the article, cntrl+F "The brain simulator reply" to find the section). Basically he's arguing that a simulated brain cannot think because all the simulation is doing is applying rules that the computer doesn't understand the background of in order to take inputs and return outputs. But in my opinion that's exactly what the brain is doing. The brain receives stimulus, causing neurons to fire, and in response to those firings other neurons fire (I'm not up to snuff on biology so if I say anything wrong here someone please jump in and correct me). Your eyes process an image of a tree, which gets transferred to neurons, which causes other neurons to activate through the connections between neurons. So how is this different from if a computer were to receive a stimulus and make connections between stored information according to rules set in place (in this example the rules would be like the connections between neurons)? I don't think it is.

Searle again refers to the Chinese room idea to refute this and likens the brain to a series of water pipes. I think he's right if we're looking at the small picture, where seeing Chinese symbols, following rules, and returning other Chinese symbols is all we're doing. That's not what we would call thought or consciousness. But that's what parts of the brain do too. Imagine someone had a severely damaged or underformed brain, so that they were blind, deaf, etc. and all their brain could handle doing was if someone touched their pointer finger they would respond by slightly bending their pinky finger. Would we call that thought or consciousness? I don't think so. I think consciousness or thought comes from the brains ability to connect a huge amount of neurons. We have a bunch of information stored there, and stimulus such as seeing an image of a tree doesn't just follow one path in the brain resulting in the bending of a pinky finger. It links to other times our brain has seen trees, information we've stored previously about trees, sounds and symbols that are stored that we use to tell others what that image is, etc. To me, that's consciousness. So I think from looking at it that way, a human has more consciousness than a gorilla, which has more consciousness than a dog, which has more than a mouse, and so on. I think thought and consciousness is dependent on how much information is stored and how connections between that information are made.

If you only look at a narrow example of a task I think it's obvious that you would conclude that computers could never have consciousness. That's what Searle does. I think he makes a lot of good points about the limitations of computers and why we're nowhere close to developing real thinking or conscious computers. But I think he misses part of the picture by only narrowly looking at one small process instead of considering that a brain that can only do one small process wouldn't be considered conscious either, it's the thousands or millions of processes that happen simultaneously and provide context that make thinking and consciousness possible.

And, of course, it's absolutely possible that I'm totally wrong about all of this, and probably even likely that I'm wrong. We still have a huge amount to learn about brains and consciousness and what life is and everything (and that's the royal we, I personally know nothing about biology and a whole bunch of other subjects). But for now this is my theory.

The specific question in my poll comes from this wikipedia article ([https://en.wikipedia.org/wiki/Chinese_room#Brain_simulation_and_connectionist_replies:_redesigning_the_room](https://en.wikipedia.org/wiki/Chinese_room#Brain_simulation_and_connectionist_replies:_redesigning_the_room), see the section called brain replacement scenario), where someone posed a new thought experiment asking the question from the poll I posted. Searle believes that your consciousness would disappear in that scenario as your brain got replaced until eventually you were totally unaware.

I was curious about his views and he seemed to be ascribing some kind of non-physical power to how brains create consciousness, so I also found this paper by him where he clarifies his view some. The short version is that he believes consciousness has special qualities because it has a first person component, as in it's something that only one person can experience. Science could identify everything about a person's consciousness and how it works, but science cannot allow two people to share in the exact experience of one consciousness. And he does think it would be possible to replicate consciousness, just not on a computer. He thinks there's more to the brain that would have to be replicated that cannot be done by simulating electrical signals on a computer. It's a really interesting article, and also very short. I highly suggest checking it out ([http://faculty.wcas.northwestern.edu/~paller/dialogue/propertydualism.pdf](http://faculty.wcas.northwestern.edu/~paller/dialogue/propertydualism.pdf)). And here's a reddit comment that really made his views a lot clearer and made the linked paper easier to understand (https://www.reddit.com/r/askphilosophy/comments/44u1h2/ontological_reduction_versus_causal_reduction/, see the top comment).